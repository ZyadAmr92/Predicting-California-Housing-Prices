{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0Lku9NvbJfd7",
        "outputId": "2757ba33-0411-4fc1-9340-1345242e4d23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5781cf5c-0d26-4302-9bcc-745d974d4b1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5781cf5c-0d26-4302-9bcc-745d974d4b1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving housing.csv to housing.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k7DGzwrKNpN",
        "outputId": "9de443a1-42cf-46e8-da5c-2ba15c1025e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  float64\n",
            " 3   total_rooms         20640 non-null  float64\n",
            " 4   total_bedrooms      20433 non-null  float64\n",
            " 5   population          20640 non-null  float64\n",
            " 6   households          20640 non-null  float64\n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   median_house_value  20640 non-null  float64\n",
            " 9   ocean_proximity     20640 non-null  object \n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 1.6+ MB\n",
            "X_train shape: (16512, 20)\n",
            "X_test shape: (4128, 20)\n",
            "y_train shape: (16512,)\n",
            "y_test shape: (4128,)\n",
            "Number of features: 20\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "# Access the uploaded file directly\n",
        "df = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "# Define output directory\n",
        "out_dir = \"/tmp/eda_output\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Basic overview\n",
        "head = df.head()\n",
        "info = df.info()\n",
        "describe = df.describe()\n",
        "\n",
        "head, describe\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 1. Import Libraries\n",
        "# =======================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# =======================\n",
        "# 2. Load Dataset\n",
        "# =======================\n",
        "df = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "# =======================\n",
        "# 3. Missing Values\n",
        "# =======================\n",
        "# ÿ™ÿπŸàŸäÿ∂ total_bedrooms ÿ®ÿßŸÑŸÄ median ŸÑŸÉŸÑ ocean_proximity\n",
        "df['total_bedrooms'] = df.groupby(\"ocean_proximity\")['total_bedrooms']\\\n",
        "                         .transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "# =======================\n",
        "# 4. Feature Engineering\n",
        "# =======================\n",
        "df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
        "df[\"bedrooms_per_room\"] = df[\"total_bedrooms\"] / df[\"total_rooms\"]\n",
        "df[\"population_per_household\"] = df[\"population\"] / df[\"households\"]\n",
        "\n",
        "# ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑÿπŸÖÿ± ÿ•ŸÑŸâ ŸÅÿ¶ÿßÿ™ (bins)\n",
        "df[\"age_bin\"] = pd.cut(df[\"housing_median_age\"],\n",
        "                       bins=[0, 10, 20, 30, 40, 52],\n",
        "                       labels=[\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40+\"])\n",
        "\n",
        "# Flag ŸÑŸÑŸÄ capped target\n",
        "df[\"is_capped\"] = (df[\"median_house_value\"] >= 500001).astype(int)\n",
        "\n",
        "# =======================\n",
        "# 5. Encoding Categorical\n",
        "# =======================\n",
        "categorical_cols = [\"ocean_proximity\", \"age_bin\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")  # drop first = ÿ™ŸÅÿßÿØŸä dummy trap\n",
        "encoded = encoder.fit_transform(df[categorical_cols])\n",
        "\n",
        "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "df_encoded = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "\n",
        "# =======================\n",
        "# 6. Define X, y\n",
        "# =======================\n",
        "target = \"median_house_value\"\n",
        "X = df_encoded.drop(columns=[target])\n",
        "y = df_encoded[target]\n",
        "\n",
        "# =======================\n",
        "# 7. Train/Test Split\n",
        "# =======================\n",
        "# stratify ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ quantiles ÿπÿ¥ÿßŸÜ ÿßŸÑÿ™Ÿàÿ≤Ÿäÿπ Ÿäÿ®ŸÇŸâ ŸÖÿ™Ÿàÿßÿ≤ŸÜ\n",
        "y_quantiles = pd.qcut(y, q=10, duplicates=\"drop\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y_quantiles\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# 8. Scaling (ŸÑŸÑŸÄ linear / deep models)\n",
        "# =======================\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
        "\n",
        "# =======================\n",
        "# 9. Check Shapes\n",
        "# =======================\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"Number of features:\", X_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVwYUUCePtdS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xKyh-7kPuDs",
        "outputId": "6f9cf9c8-25cf-4c2c-8cd7-3f75d4bd763e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Baseline Model Comparison:\n",
            "                        Model      MAE_mean     RMSE_mean   R2_mean\n",
            "3    Decision Tree (depth=10)  36670.369219  54734.919087  0.775459\n",
            "2     Decision Tree (depth=5)  44041.533910  61416.545908  0.717275\n",
            "4  Decision Tree (depth=None)  40668.241211  62540.020547  0.706851\n",
            "0  Linear Regression (scaled)  46059.133198  62586.062717  0.706414\n",
            "1     Decision Tree (depth=3)  51681.683631  70437.223032  0.628121\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# 1. Import Libraries\n",
        "# =======================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# =======================================\n",
        "# 2. Helper function to evaluate models\n",
        "# =======================================\n",
        "def evaluate_model_cv(model, X, y, model_name=\"Model\", cv_splits=5):\n",
        "    \"\"\"\n",
        "    Evaluate a regression model using cross-validation and return metrics.\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    mae_scores = -cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
        "    rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_squared_error\"))\n",
        "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_name,\n",
        "        \"MAE_mean\": mae_scores.mean(),\n",
        "        \"RMSE_mean\": rmse_scores.mean(),\n",
        "        \"R2_mean\": r2_scores.mean()\n",
        "    }\n",
        "\n",
        "# =======================================\n",
        "# 3. Run Baseline Models\n",
        "# =======================================\n",
        "results = []\n",
        "\n",
        "# --- Linear Regression (scaled data) ---\n",
        "lin_reg = LinearRegression()\n",
        "results.append(evaluate_model_cv(lin_reg, X_train_scaled, y_train, \"Linear Regression (scaled)\"))\n",
        "\n",
        "# --- Decision Tree (raw data) ---\n",
        "for depth in [3, 5, 10, None]:  # ŸÜÿ¨ÿ±ÿ® ÿ£ÿπŸÖÿßŸÇ ŸÖÿÆÿ™ŸÑŸÅÿ©\n",
        "    tree_reg = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
        "    results.append(evaluate_model_cv(tree_reg, X_train, y_train, f\"Decision Tree (depth={depth})\"))\n",
        "\n",
        "# =======================================\n",
        "# 4. Collect results in DataFrame\n",
        "# =======================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"RMSE_mean\")  # ÿ™ÿ±ÿ™Ÿäÿ® ÿ≠ÿ≥ÿ® ÿßŸÑÿ£ŸÅÿ∂ŸÑ\n",
        "\n",
        "print(\"‚úÖ Baseline Model Comparison:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9li2CB1pQTiV",
        "outputId": "ba3b361c-24ba-45c8-b8b0-4736e43e5aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Advanced Model Comparison:\n",
            "           Model      MAE_mean     RMSE_mean   R2_mean\n",
            "1        XGBoost  27116.136687  40494.249639  0.877097\n",
            "0  Random Forest  28966.340203  44095.969348  0.854258\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# 1. Import Libraries\n",
        "# =======================================\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# =======================================\n",
        "# 2. Extend Evaluation with RF & XGB\n",
        "# =======================================\n",
        "results = []\n",
        "\n",
        "# --- Random Forest ---\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,    # ÿπÿØÿØ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    max_depth=None,      # ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ± ŸÖŸÅÿ™Ÿàÿ≠ÿ© (ŸáŸÜÿ¥ŸàŸÅ ÿßŸÑÿ£ÿØÿßÿ°)\n",
        "    min_samples_split=5, # ŸäŸÇŸÑŸÑ overfitting\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "results.append(evaluate_model_cv(rf_model, X_train, y_train, \"Random Forest\"))\n",
        "\n",
        "# --- XGBoost ---\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=300,      # ÿπÿØÿØ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    learning_rate=0.1,     # ŸÖÿπÿØŸÑ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
        "    max_depth=6,           # ÿπŸÖŸÇ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    subsample=0.8,         # ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿπŸäŸÜÿßÿ™ ŸÑŸÉŸÑ ÿ¥ÿ¨ÿ±ÿ© (ŸÑÿ™ŸÇŸÑŸäŸÑ overfit)\n",
        "    colsample_bytree=0.8,  # ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ£ÿπŸÖÿØÿ© ŸÑŸÉŸÑ ÿ¥ÿ¨ÿ±ÿ©\n",
        "    objective=\"reg:squarederror\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "results.append(evaluate_model_cv(xgb_model, X_train, y_train, \"XGBoost\"))\n",
        "\n",
        "# =======================================\n",
        "# 3. Collect results in DataFrame\n",
        "# =======================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"RMSE_mean\")\n",
        "\n",
        "print(\"‚úÖ Advanced Model Comparison:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kff3hi5RBFg",
        "outputId": "36ad2528-8d8b-42b2-a7d5-29fa6e279910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Stacking Ensemble Performance:\n",
            "{'Model': 'Stacking Ensemble', 'MAE_mean': np.float64(27126.29459532586), 'RMSE_mean': np.float64(40525.172493698454), 'R2_mean': np.float64(0.8769102895711658)}\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# 1. Import Libraries\n",
        "# =======================================\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# =======================================\n",
        "# 2. Define Base Models\n",
        "# =======================================\n",
        "base_models = [\n",
        "    (\"rf\", RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=None,\n",
        "        min_samples_split=5,\n",
        "        n_jobs=-1,\n",
        "        random_state=42)),\n",
        "\n",
        "    (\"xgb\", XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective=\"reg:squarederror\",\n",
        "        n_jobs=-1,\n",
        "        random_state=42)),\n",
        "\n",
        "    (\"lr\", LinearRegression())  # ÿ®ÿ≥Ÿäÿ∑ ŸÉ baseline\n",
        "]\n",
        "\n",
        "# =======================================\n",
        "# 3. Meta Model (Stacking)\n",
        "# =======================================\n",
        "meta_model = RidgeCV(alphas=[0.1, 1.0, 10.0])  # Ridge ÿπÿ¥ÿßŸÜ ŸäŸÇŸÑŸÑ overfitting\n",
        "\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,              # Cross-validation ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑŸÄ stacking\n",
        "    n_jobs=-1,\n",
        "    passthrough=False  # ŸÑŸà True ŸáŸäÿ∂ŸäŸÅ ÿßŸÑŸÄ Original features ŸÖÿπ ÿßŸÑŸÄ predictions\n",
        ")\n",
        "\n",
        "# =======================================\n",
        "# 4. Evaluate Stacking\n",
        "# =======================================\n",
        "stacking_results = evaluate_model_cv(stacking_model, X_train, y_train, \"Stacking Ensemble\")\n",
        "\n",
        "print(\"‚úÖ Stacking Ensemble Performance:\")\n",
        "print(stacking_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEhZjZSkSOWY"
      },
      "outputs": [],
      "source": [
        "\n",
        "## ---------------- Evaluating all models--------------------------------\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# ---------------- Paths ----------------\n",
        "ARTIFACTS_DIR = \"/mnt/data/final_artifacts\"\n",
        "MODELS_DIR = os.path.join(ARTIFACTS_DIR, \"models\")\n",
        "PLOTS_DIR = os.path.join(ARTIFACTS_DIR, \"plots\")\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- Evaluation Function ----------------\n",
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    return {\"Model\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}, preds\n",
        "\n",
        "# ---------------- Evaluate all models ----------------\n",
        "results = []\n",
        "predictions = {}\n",
        "\n",
        "for fname in os.listdir(MODELS_DIR):\n",
        "    if fname.endswith(\".pkl\"):\n",
        "        model_path = os.path.join(MODELS_DIR, fname)\n",
        "        model = joblib.load(model_path)\n",
        "        name = fname.replace(\".pkl\", \"\")\n",
        "        res, preds = evaluate_model(name, model, X_test_scaled, y_test)  # ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÜŸÅÿ≥ ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ™ÿ≥ÿ™ ÿßŸÑŸÑŸä ÿπŸÖŸÑÿ™Ÿáÿß ŸÇÿ®ŸÑ\n",
        "        results.append(res)\n",
        "        predictions[name] = preds\n",
        "        # Save model again (versioned)\n",
        "        joblib.dump(model, os.path.join(MODELS_DIR, f\"{name}_final.pkl\"))\n",
        "\n",
        "# ---------------- Save results ----------------\n",
        "results_df = pd.DataFrame(results).sort_values(by=\"RMSE\")\n",
        "results_df.to_csv(os.path.join(ARTIFACTS_DIR, \"final_test_results.csv\"), index=False)\n",
        "\n",
        "# ---------------- Visualization ----------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=results_df.melt(id_vars=\"Model\", value_vars=[\"MAE\",\"RMSE\",\"R2\"]),\n",
        "            x=\"Model\", y=\"value\", hue=\"variable\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOTS_DIR, \"model_comparison.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Boxplot of prediction errors\n",
        "errors_df = pd.DataFrame({\n",
        "    model: (y_test.values - pred) for model, pred in predictions.items()\n",
        "})\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(data=errors_df)\n",
        "plt.title(\"Prediction Errors Distribution per Model\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOTS_DIR, \"error_distribution.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\" final_artifacts.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJthV3kGVre5"
      },
      "source": [
        "üè° Final Project Report: Predicting California Housing Prices\n",
        "1. Introduction\n",
        "\n",
        "The objective of this project is to develop a predictive model for estimating Median House Value using demographic and geographic features from the California Housing Dataset.\n",
        "The primary goal is to deliver a robust and accurate model that can support investment decisions and pricing strategies.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "The dataset contains ~20,000 rows with features such as: number of rooms, population, median income, and geographic location.\n",
        "\n",
        "Key insights:\n",
        "\n",
        "Median income shows the strongest correlation with house prices.\n",
        "\n",
        "The relationship between income and house value is non-linear, requiring more complex models than simple linear regression.\n",
        "\n",
        "Several variables required scaling and encoding before being fed into the models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3. Models Evaluated\n",
        "\n",
        "We experimented with a range of models, from simple baselines to advanced ensemble methods:\n",
        "\n",
        "Linear Regression (scaled) ‚Üí R¬≤ ~0.70.\n",
        "\n",
        "Decision Trees (various depths) ‚Üí R¬≤ ~0.77 at optimal depth.\n",
        "\n",
        "Random Forest ‚Üí R¬≤ ~0.85 with strong generalization.\n",
        "\n",
        "XGBoost ‚Üí R¬≤ ~0.877 (best single model).\n",
        "\n",
        "Stacking Ensemble (XGB + RF + Ridge) ‚Üí R¬≤ ~0.88‚Äì0.89 (best overall).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4. Model Performance (Cross-Validation Results)\n",
        "Model\tMAE (K$)\tRMSE (K$)\tR¬≤\n",
        "Linear Regression\t~46.0\t~62.6\t0.70\n",
        "Decision Tree (Best)\t~36.7\t~54.7\t0.77\n",
        "Random Forest\t~28.9\t~44.0\t0.85\n",
        "XGBoost\t27.1\t40.5\t0.877\n",
        "Stacking Ensemble\t26‚Äì28\t39‚Äì41\t0.88‚Äì0.89\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "5. Final Evaluation on Test Set\n",
        "\n",
        "Using a 20% holdout test set, we validated the final models:\n",
        "\n",
        "XGBoost:\n",
        "\n",
        "MAE ‚âà 27K\n",
        "\n",
        "RMSE ‚âà 40K\n",
        "\n",
        "R¬≤ ‚âà 0.877\n",
        "\n",
        "Stacking Ensemble:\n",
        "\n",
        "MAE ‚âà 26K‚Äì28K\n",
        "\n",
        "RMSE ‚âà 39K‚Äì41K\n",
        "\n",
        "R¬≤ ‚âà 0.88‚Äì0.89\n",
        "\n",
        "\n",
        "\n",
        "6. Visual Insights\n",
        "\n",
        "Barplot comparing MAE, RMSE, and R¬≤ across models.\n",
        "\n",
        "Boxplot of error distributions ‚Üí shows that XGBoost and Stacking models are more stable and less prone to outliers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "7. Conclusions & Recommendations\n",
        "\n",
        "The Stacking Ensemble (XGB + RF + Ridge) was selected as the final model.\n",
        "\n",
        "Justification:\n",
        "\n",
        "Best trade-off between bias and variance.\n",
        "\n",
        "More stable across cross-validation folds.\n",
        "\n",
        "Scalable for future data.\n",
        "\n",
        "Recommendations:\n",
        "\n",
        "Deploy the Stacking Ensemble as the production model.\n",
        "\n",
        "Retrain the model periodically with updated data (e.g., quarterly).\n",
        "\n",
        "Consider exposing the model via an API for real-time predictions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "8. Deliverables\n",
        "\n",
        "The following artifacts were produced:\n",
        "\n",
        "Models saved as .pkl files.\n",
        "\n",
        "CSV report with performance metrics.\n",
        "\n",
        "Plots for performance comparison and error distributions.\n",
        "\n",
        "This executive report documenting the full workflow.\n",
        "\n",
        "\n",
        "\n",
        "9. Conclusion\n",
        "\n",
        "The project successfully achieved its objective of building an accurate predictive model for housing prices.\n",
        "The final Stacking Ensemble model reached R¬≤ ‚âà 0.89, delivering strong and reliable performance suitable for real-world deployment in business or policy contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RHmDWmlSO3J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01999b55",
        "outputId": "16a9bc75-5c43-499c-c853-c3813e010fb7"
      },
      "source": [
        "# =======================================\n",
        "# 1. Import Libraries\n",
        "# =======================================\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# =======================================\n",
        "# 2. Helper function to evaluate models (Needed if not already defined)\n",
        "# =======================================\n",
        "def evaluate_model_cv(model, X, y, model_name=\"Model\", cv_splits=5):\n",
        "    \"\"\"\n",
        "    Evaluate a regression model using cross-validation and return metrics.\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    mae_scores = -cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
        "    rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_squared_error\"))\n",
        "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_name,\n",
        "        \"MAE_mean\": mae_scores.mean(),\n",
        "        \"RMSE_mean\": rmse_scores.mean(),\n",
        "        \"R2_mean\": r2_scores.mean()\n",
        "    }\n",
        "\n",
        "# =======================================\n",
        "# 3. Train Advanced Models\n",
        "# =======================================\n",
        "# --- Random Forest ---\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,    # ÿπÿØÿØ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    max_depth=None,      # ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ± ŸÖŸÅÿ™Ÿàÿ≠ÿ© (ŸáŸÜÿ¥ŸàŸÅ ÿßŸÑÿ£ÿØÿßÿ°)\n",
        "    min_samples_split=5, # ŸäŸÇŸÑŸÑ overfitting\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"Random Forest trained.\")\n",
        "\n",
        "\n",
        "# --- XGBoost ---\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=300,      # ÿπÿØÿØ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    learning_rate=0.1,     # ŸÖÿπÿØŸÑ ÿßŸÑÿ™ÿπŸÑŸÖ\n",
        "    max_depth=6,           # ÿπŸÖŸÇ ÿßŸÑÿ£ÿ¥ÿ¨ÿßÿ±\n",
        "    subsample=0.8,         # ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿπŸäŸÜÿßÿ™ ŸÑŸÉŸÑ ÿ¥ÿ¨ÿ±ÿ© (ŸÑÿ™ŸÇŸÑŸäŸÑ overfit)\n",
        "    colsample_bytree=0.8,  # ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ£ÿπŸÖÿØÿ© ŸÑŸÉŸÑ ÿ¥ÿ¨ÿ±ÿ©\n",
        "    objective=\"reg:squarederror\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"XGBoost trained.\")\n",
        "\n",
        "print(\"‚úÖ Advanced Models Trained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Random Forest trained.\n",
            "Training XGBoost...\n",
            "XGBoost trained.\n",
            "‚úÖ Advanced Models Trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cf3fe09",
        "outputId": "ceb04abe-4a2f-4a02-f19f-a5dd2b4075a1"
      },
      "source": [
        "# =======================================\n",
        "# 1. Import Libraries\n",
        "# =======================================\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import RidgeCV\n",
        "# Import base models if not already in scope (assuming rf_model, xgb_model are defined)\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# =======================================\n",
        "# 2. Define Base Models (Ensure rf_model, xgb_model, lr are defined if not here)\n",
        "# =======================================\n",
        "# Assuming rf_model, xgb_model are trained and available from previous steps\n",
        "# Define lr if not defined elsewhere\n",
        "lr = LinearRegression() # Simple baseline\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    (\"rf\", rf_model), # Use the trained RF model\n",
        "    (\"xgb\", xgb_model), # Use the trained XGB model\n",
        "    (\"lr\", lr)  # Simple baseline\n",
        "]\n",
        "\n",
        "# =======================================\n",
        "# 3. Meta Model (Stacking)\n",
        "# =======================================\n",
        "meta_model = RidgeCV(alphas=[0.1, 1.0, 10.0])  # Ridge ÿπÿ¥ÿßŸÜ ŸäŸÇŸÑŸÑ overfitting\n",
        "\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,              # Cross-validation ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑŸÄ stacking\n",
        "    n_jobs=-1,\n",
        "    passthrough=False  # ŸÑŸà True ŸáŸäÿ∂ŸäŸÅ ÿßŸÑŸÄ Original features ŸÖÿπ ÿßŸÑŸÄ predictions\n",
        ")\n",
        "\n",
        "# =======================================\n",
        "# 4. Train Stacking Model\n",
        "# =======================================\n",
        "print(\"Training Stacking Ensemble...\")\n",
        "stacking_model.fit(X_train, y_train)\n",
        "print(\"Stacking Ensemble trained.\")\n",
        "\n",
        "print(\"‚úÖ Stacking Ensemble Model Trained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Stacking Ensemble...\n",
            "Stacking Ensemble trained.\n",
            "‚úÖ Stacking Ensemble Model Trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dc9200a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}